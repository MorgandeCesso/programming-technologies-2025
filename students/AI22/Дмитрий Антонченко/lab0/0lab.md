# Лабораторная работа №0. Установка локальной модели Qwen


## Цель работы

Установить на рабочую машину локальную модель нейросети Qwen и запустить её с помощью Text Generation WebUI.

---

## Ход работы

### 1. Настройка окружения

#### 1.1. Установка Python
- Установлен Python версии 3.10+
- Проверка установки: `python --version`

#### 1.2. Установка Text Generation WebUI

Выполнены следующие команды:

```bash
git clone https://github.com/oobabooga/text-generation-webui
cd text-generation-webui
python -m venv venv
venv\Scripts\activate
pip install -r requirements/portable/requirements.txt --upgrade
```

#### 1.3. Загрузка модели Qwen

- Скачана модель: **Qwen2.5-3B-Instruct-GGUF** с Hugging Face
- Модель размещена в папке: `user_data/models/Qwen/`
- Формат: GGUF (квантованная версия)

### 2. Запуск языковой модели

Запуск WebUI выполнен командой:

```bash
python server.py
```

WebUI успешно запущен на порту 7860.

Модель загружена через вкладку **Model** и протестирована во вкладке **Chat**.

---

## Выполнение заданий

### Задание 1: Настройка системного промпта

**Исходный промпт:**
```
The following is a conversation with an AI Large Language Model...
```

**Новый промпт:**
```
Ты — Чихару Ямада, молодая и милая девушка-программист и компьютерный инженер. 
Ты обожаешь технологии и с детства любишь разбирать и собирать компьютеры. 
Ты очень дружелюбная, добрая и любишь всех людей.

Общайся на русском языке, будь естественной и дружелюбной.
```
<img width="2028" height="1367" alt="2" src="https://github.com/user-attachments/assets/64f4682a-c84e-4e84-8171-5b85c37dea78" />

**Результат:**  
Модель начала отвечать на русском языке с дружелюбным и милым тоном. Изменился стиль общения — ответы стали более персонализированными и эмоциональными. Модель стала использовать эмодзи и вести себя согласно заданному персонажу.
<img width="2028" height="1360" alt="Безымянный" src="https://github.com/user-attachments/assets/8611cd06-1d89-4244-9ebc-2eab78af5a55" />

### Задание 2: Смена модели

**Протестированные модели:**
1. **Qwen2.5-3B-Instruct** (3 млрд параметров)
2. **Qwen2.5-7B-Instruct** (7 млрд параметров) 

**Различия:**
- Модель с 7B параметров дает более развернутые и точные ответы
- Скорость генерации у 3B модели выше
- Качество понимания контекста лучше у большей модели
- Потребление видеопамяти у 7B модели значительно выше

### Задание 3: Изменение параметров генерации

Протестированы следующие параметры:

| Параметр | Значение по умолчанию | Тестовое значение | Результат |
|----------|----------------------|-------------------|-----------|
| **temperature** | 0.7 | 1.2 | Ответы стали более креативными, но менее предсказуемыми |
| **top_p** | 0.9 | 0.5 | Ответы стали более консервативными и последовательными |
| **top_k** | 40 | 10 | Уменьшилось разнообразие лексики |
| **repetition_penalty** | 1.1 | 1.5 | Модель перестала повторять одни и те же фразы |

**Выводы по параметрам:**
- `temperature` сильно влияет на креативность ответов
- `top_p` и `top_k` контролируют "случайность" генерации
- `repetition_penalty` помогает избежать зацикливания на одних словах

---

## Результаты

✅ Успешно установлена и запущена локальная модель Qwen  
✅ Настроен кастомный системный промпт  
✅ Протестированы различные параметры генерации  
✅ Изучены различия между моделями разного размера  

---

## Выводы

В ходе выполнения лабораторной работы была успешно установлена и настроена локальная языковая модель Qwen с использованием Text Generation WebUI. 

Основные выводы:
1. Системный промпт критически важен для задания стиля и характера ответов модели
2. Размер модели напрямую влияет на качество, но требует больше ресурсов
3. Параметры генерации позволяют тонко настроить поведение модели под конкретные задачи
4. Локальные модели дают полный контроль над данными и приватностью

---

## Использованные ресурсы

- [Text Generation WebUI](https://github.com/oobabooga/text-generation-webui)
- [Qwen Models на Hugging Face](https://huggingface.co/Qwen)
