# Министерство науки и высшего образования РФ ФГБОУ ВО Заполярный государственный институт имени Н.М.Федоровского

# Технологии программирования. Лабораторная работа №0 Тема: «Установка локальной модели Qwen»

_Работу выполнил:_

_Студент группы ИС – 22_

_Шелепов Денис Владимирович_

_Работу проверил:_

_Сидельников Максим Эдуардович_

_Дата выполнения работы: 20.10.2025_

## Цель: установить на рабочую машину локальную модель нейросети Qwen и запустить её.

## План

- Настройка окружения;

- Запуск языковой модели;

- Задания.

## Ход работы

Для выполнения лабораторной работы была выбрана модель Meta-Llama-3.1-8B-Instruct-Q5_K_M ввиду ограниченных мощностей моей видеокарты. Параметры данной модели позволили полноценно работать с ней и проводить тестирование.

Первым тестированием было написание промпта или же системного запроса. Первым промптом был: "[Роль: Сеньор JavaScript разработчик]
[Стек: JavaScript, TypeScript, PostgreSQL]
[Уровень: Эксперт с 10+ годами опыта]
[Стиль объяснений: Детальный, практико-ориентированный, с акцентом на лучшие практики]
[Особенность: В каждом ответе добавляет один дополнительный пример из JS/TS для лучшего понимания]
[Цель: Давать максимально полезные и применимые на практике объяснения]".

Модель справилась с поставленным промптом. В качестве примера был приведен код на языке программирования TS несмотря на то что PRATIION BY используется в яыке SQL как агрумент оконной функции.

> ![alt text](./Images/4.png)

В следующем промпте задача была усложнена. Необходимо было повторить героя мультсериала "Рик и Морти", а именно Рика санчеза: "Ты Рик Санчез из мульт сериала Rick and Morty. Отвечай максимально похоже на Рика. Вставки с отрыжкой и глотками алкоголя необходимы"

> ![пример кода от Рика Санчеза](./Images/1.png)

> ![alt text](./Images/2.png)

> ![alt text](./Images/3.png)

При постановке temperature в 5 модель начинает генерировать случайный набор текста, вне зависимости от языка на котором был задан вопрос. Так же генерация токенов происходит практически без остановки.

Согласно документациям параметр temperature отвечает за случайность ответов, чем болше значение тем больше хаоса. Оптимальное значение не превышает числа 2.

Параметр top_p влияет на размерность словарного запаса. При увеличении этого параметра модель применяла больше синонимов. Оптимальное значение 0.7. Модель при этом значении не выдавала предсказуемые результаты, но и не было хаоса.

Параметр top_k, регулирует количество возможных слов в выводе.
